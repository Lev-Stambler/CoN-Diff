\documentclass[11pt]{article}
\usepackage{CSTheoryToolkitCMUStyle}
\usepackage{Custom}
\usepackage{cleveref}
% \usepackage{biblatex}
% \addbibresource{CSTheoryToolkitCMUStyle.bib}



%%%%% Stuff you can change %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\myname}{Lev Stambler}

%%%%% Section-renaming code by egreg
\makeatletter
% we use \prefix@<level> only if it is defined
\renewcommand{\@seccntformat}[1]{%
  \ifcsname prefix@#1\endcsname
    \csname prefix@#1\endcsname
  \else
    \csname the#1\endcsname\quad
  \fi}
% Now we define our homework section prefixes
\makeatother
%%%%%

\begin{document}

\title{CoN Diff: Verified Pseudo-Correlated Noise for Differential Privacy}

% \author{\myname}

\date{\today}
\maketitle

\input{sections/commands}

%\begin{abstract}
%\end{abstract}

\section{Introduction}
\sam{Fill in}
\begin{itemize}
    \item \textbf{Motivation:} Explain the importance of noise generation for privacy-preserving mechanisms, particularly in Zero-Knowledge proofs.
    \item \textbf{Overview of ZKPs:} Briefly introduce Zero-Knowledge proofs and their significance in cryptographic protocols.
    \item \textbf{Pseudo-correlated Generators:} Define and explain pseudo-correlated generators and their role in data privacy.
\end{itemize}

\section{Background and Related Work}
\sam{Fill in}
\begin{itemize}
    \item \textbf{Noise in Cryptography:} Overview of how noise is used in cryptographic primitives (e.g., homomorphic encryption, differential privacy).
    \item \textbf{Pseudo-random and Pseudo-correlated Generators:} Key definitions, mathematical formulations, and examples.
    \item \textbf{Zero-Knowledge Proofs:} Detailed review of Zero-Knowledge proof systems and their application in verifying noisy data.
    \item \textbf{Related Work:} Survey of relevant literature on noise-based privacy mechanisms and ZKPs.
\end{itemize}

\subsection{Differential Privacy}
There are a few different ways to formally describe differntial privacy.
For simplicity, we will use the $(\eps, \delta)$-differential privacy definition, though our ideas can be extended to other definitions.

Intuitively, we can think of differential privacy as being a sort of ``2-wise'' independence condition on the input data: if we replace \emph{one} of the user's piece of data with some other possible piece of data, then differential privacy gaurentees that an adversary \emph{cannot} distinguish between the two datasets up to some probabality.

Though not cryptographic in nature, differential privacy offers a notion of ``plausible-deniability'' which can also be generalized to a more $k$-wise independent setting \lev{TODO: cite?}.

We have two flavors of differential privacy: local and non-local (or centralized) which is classical differential privacy.


\lev{IDK if this is the actual defn}
\begin{definition}[$(\eps, \delta)$ Differential Privacy,~\cite{Bassily_2015}]
	Let $\eps > 0$ and $\calX$ be the domain of the data.
	Then, a randomized algorithm, $\calM : \calX^n \rightarrow \calM(\calX)$ which is applied to a dataset of $n$ elements satisfies $(\eps, \delta)$-differential privacy if and only if for all $\vec{x} \in \calX^n$ and $\vec{x}'$ where $\vec{x'}_i \neq \vec{x}_i$ for a specific $i$,
	\[
		\Pr[\calM(\vec{x}) \in S] \leq e^\eps \Pr[\calM(\vec{x}') \in S] + \delta
	\]
	for any possible $S \subseteq \text{Range}(\calM)$.
\end{definition}

Note that in the above, the randomized algorithm $\calM$ is applied globally.
We can also deffine differential privacy locally:

\begin{definition}[$(\eps, \delta)$-Local Differential Privacy,~\cite{Bassily_2015}]
	Let $\eps > 0$ and $\calX$ be the domain of the data.
	Then, a randomized algorithm, $\calM_{loc} : \calX \rightarrow \calM_{loc}(\calX)$ which is applied to the data independently satisfies $(\eps, \delta)$-local differential privacy if and only if for all pairs $x, x' \in \calX$
	for any possible $S \subseteq \text{Range}(\calM_{loc})$, we have
	\[
		\Pr[\calM_{loc}(x) \in S] \leq e^\eps \Pr[\calM_{loc}(x') \in S] + \delta.
	\]
\end{definition}

Non-local and local differential privacy are usually achieved by adding noise to a dataset.
Though many mechanisms exist, we will outline the \emph{Laplace Mechanism} for non-local differential privacy.

Let $f: \mathcal{X}^n \rightarrow \R^d$ be some query associated with the all of the user's data (e.g. learning the mean of the data).
Then, as outlined in \cite{Bassily_2015}, for any $x$,
\[
	\calM(\vec{x}) = f(\vec{x}) + N
\]
where $N \sim Lap(0, \Delta f/ \eps)^{d}$ where $\Delta f$ is the $\ell_1$ sensitivity of $f$.
Analogously, we can think of local-differential privacy as \[
	\calM(x) = f(x) + N.
\]

\textbf{Problem with Differential Privacy:} Non-local differential privacy requires trusting some centralized aggregator.
For example, in federated learning, each party would have to send there updated gradients \emph{in the clear} to an aggregator.
Recent work \lev{TODO CITE} shows that an aggregator can almost perfectly recover the users' data from the gradient delta which could yeild a large privacy violation.
On the other hand, local differential privacy preserves users' privacy but the quality of the data degrades with an increase in the number of users.
Specifically, imagine trying to compute the sum of a dataset with $n$ users.
If each user adds Laplacian noise with a constant standard deviation, $\Delta$, then the sum of the data (calculated by adding together all of the noisy inputs from each user) has Laplacian noise with paramater $n \Delta$!

\subsection{Cryptographic Approaches}
The other primary privacy preserving mechanism in machine learning is multi-party computation (MPC \lev{CITE}), which is known as as secure multi-party computation (SMPC) in machine learning to disambiguate from massive parallel computation.
We draw from a recent survey on SMPC~\cite{zhou2024secure}.
Given that our work is focused on differential privacy, we will not formally define SMPC here.
Rather, SMPC is a cryptographic protocol which allows multiple parties to compute a function on their private data without revealing their data to each other.
SMPC can also be integrated with other cryptogrpahic techniques (such as cut-and-choose type proofs, \lev{CITE}) to provide additional security guarantees: such as integrity checks on the data.

Unfortunately, SMPC is not a panacea.
Specifically, SMPC, especially with \emph{integrity checks on the input data}, is very slow and cannot scale to large datasets and hard computations.
Moreover, practical implementations require a lot of interaction between the parties, which can be a bottleneck in some applications \cite{zhao2019secure}.


\section{Problem Definition}
We draw heavily from a recent survey on Local Differential Privacy (LDP)~\cite{yang2023local}.
\lev{Lev}
\begin{itemize}
    \item \textbf{Noise Generation:} Formal problem statement describing the generation of noise using pseudo-correlated generators.
    \item \textbf{Objective:} The goal is to verify that the generated noise satisfies the desired properties while maintaining privacy and correctness in Zero-Knowledge proofs.
\end{itemize}

\section{Methodology}
\lev{Lev}
\begin{itemize}
    \item \textbf{Pseudo-Correlated Generators:} Detailed description of the algorithm for generating noise.
    \item \textbf{Zero-Knowledge Protocol:} Explain how Zero-Knowledge proofs are used to verify the correctness of the noise.
    \item \textbf{Verification Scheme:} Present the mathematical framework for verifying the pseudo-correlated noise without revealing the underlying data.
    \item \textbf{Security Assumptions:} Discuss any assumptions required for the security of the proposed system.
\end{itemize}

\section{Implementation}
\lev{Lev}
\begin{itemize}
    \item \textbf{Experimental Setup:} Describe how to simulate the generation of pseudo-correlated noise and the Zero-Knowledge verification protocol.
    \item \textbf{Tools:} Mention the libraries, languages (e.g., Python, C++), or frameworks used.
    \item \textbf{Complexity Analysis:} Analyze the time complexity and efficiency of the noise generation and verification process.
\end{itemize}

\section{Results}
\lev{Lev}
\begin{itemize}
    \item \textbf{Verification of Noise:} Present the results of verifying the pseudo-correlated noise in the Zero-Knowledge framework.
    \item \textbf{Performance:} Compare the performance of the proposed method with existing noise-based mechanisms.
    \item \textbf{Security:} Evaluate the security guarantees provided by the proposed system.
\end{itemize}

\section{Conclusion and Future Work}
\lev{Lev}
\begin{itemize}
    \item Summarize the findings and contributions of the project.
    \item Suggest potential improvements or extensions to the current system.
\end{itemize}

\bibliographystyle{alpha}
\bibliography{bib/ref}

\end{document}

